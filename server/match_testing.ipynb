{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "021c092e968312d3dab0e2b342106c6ea33af2822bb47356036b17e5b370d2de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Home Match Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Google Cloud Vision API Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io \n",
    "import os \n",
    "\n",
    "from google.cloud import vision\n",
    "# /Users/sterlinggamble/Downloads/home-match-316216-b03a318ee037.json export GOOGLE_APPLICATION_CREDENTIALS=\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "credential_path = \"/Users/sterlinggamble/Downloads/home-match-316216-b03a318ee037.json\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = credential_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiates a client\n",
    "client = vision.ImageAnnotatorClient()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.abspath('test_images/modern1.jpg')\n",
    "# loads image into memory\n",
    "with io.open(file_name, 'rb') as image_file:\n",
    "    content = image_file.read()\n",
    "\n",
    "image = vision.Image(content=content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs label detection on the image file\n",
    "response = client.label_detection(image=image)\n",
    "labels = response.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[mid: \"/m/05s2s\"\n",
       "description: \"Plant\"\n",
       "score: 0.9686179757118225\n",
       "topicality: 0.9686179757118225\n",
       ", mid: \"/m/0cgh4\"\n",
       "description: \"Building\"\n",
       "score: 0.9671809077262878\n",
       "topicality: 0.9671809077262878\n",
       ", mid: \"/m/01bqvp\"\n",
       "description: \"Sky\"\n",
       "score: 0.9519641399383545\n",
       "topicality: 0.9519641399383545\n",
       ", mid: \"/m/05wrt\"\n",
       "description: \"Property\"\n",
       "score: 0.9432652592658997\n",
       "topicality: 0.9432652592658997\n",
       ", mid: \"/m/0d4v4\"\n",
       "description: \"Window\"\n",
       "score: 0.9091912508010864\n",
       "topicality: 0.9091912508010864\n",
       ", mid: \"/m/03jm5\"\n",
       "description: \"House\"\n",
       "score: 0.8875491619110107\n",
       "topicality: 0.8875491619110107\n",
       ", mid: \"/m/07j7r\"\n",
       "description: \"Tree\"\n",
       "score: 0.8841086030006409\n",
       "topicality: 0.8841086030006409\n",
       ", mid: \"/m/0csby\"\n",
       "description: \"Cloud\"\n",
       "score: 0.8794347643852234\n",
       "topicality: 0.8794347643852234\n",
       ", mid: \"/m/02dgv\"\n",
       "description: \"Door\"\n",
       "score: 0.8673933744430542\n",
       "topicality: 0.8673933744430542\n",
       ", mid: \"/m/04wnmd\"\n",
       "description: \"Fixture\"\n",
       "score: 0.8663341999053955\n",
       "topicality: 0.8663341999053955\n",
       "]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.image_properties(image=image)\n",
    "props = response.image_properties_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dominant_colors {\n",
       "  colors {\n",
       "    color {\n",
       "      red: 102.0\n",
       "      green: 83.0\n",
       "      blue: 57.0\n",
       "    }\n",
       "    score: 0.11266886442899704\n",
       "    pixel_fraction: 0.01679999940097332\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 120.0\n",
       "      green: 71.0\n",
       "      blue: 32.0\n",
       "    }\n",
       "    score: 0.10657645761966705\n",
       "    pixel_fraction: 0.0015999999595806003\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 147.0\n",
       "      green: 121.0\n",
       "      blue: 72.0\n",
       "    }\n",
       "    score: 0.04780112951993942\n",
       "    pixel_fraction: 0.0006000000284984708\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 103.0\n",
       "      green: 125.0\n",
       "      blue: 91.0\n",
       "    }\n",
       "    score: 0.04712723195552826\n",
       "    pixel_fraction: 0.05013333261013031\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 195.0\n",
       "      green: 196.0\n",
       "      blue: 193.0\n",
       "    }\n",
       "    score: 0.0429004468023777\n",
       "    pixel_fraction: 0.2019333392381668\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 84.0\n",
       "      green: 84.0\n",
       "      blue: 79.0\n",
       "    }\n",
       "    score: 0.06205977872014046\n",
       "    pixel_fraction: 0.04479999840259552\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 53.0\n",
       "      green: 51.0\n",
       "      blue: 47.0\n",
       "    }\n",
       "    score: 0.057032227516174316\n",
       "    pixel_fraction: 0.0435333326458931\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 26.0\n",
       "      green: 24.0\n",
       "      blue: 22.0\n",
       "    }\n",
       "    score: 0.05330726131796837\n",
       "    pixel_fraction: 0.03553333505988121\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 61.0\n",
       "      green: 50.0\n",
       "      blue: 29.0\n",
       "    }\n",
       "    score: 0.04005545750260353\n",
       "    pixel_fraction: 0.011066666804254055\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 128.0\n",
       "      green: 114.0\n",
       "      blue: 91.0\n",
       "    }\n",
       "    score: 0.03860282897949219\n",
       "    pixel_fraction: 0.010400000028312206\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "props"
   ]
  },
  {
   "source": [
    "### Test With Public Image URL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import vision_v1"
   ]
  },
  {
   "source": [
    "\"\"\"\n",
    "Request with URL example\n",
    "{\n",
    "  \"requests\":[\n",
    "    {\n",
    "      \"image\":{\n",
    "        \"source\":{\n",
    "          \"imageUri\":\n",
    "            \"https://www.google.com/images/branding/googlelogo/2x/googlelogo_color_272x92dp.png\"\n",
    "        }\n",
    "      },\n",
    "      \"features\":[\n",
    "        {\n",
    "          \"type\":\"LOGO_DETECTION\",\n",
    "          \"maxResults\":1\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modern house from google images\n",
    "image_url = \"https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/brewster-mcleod-architects-1486154143.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = vision.ImageAnnotatorClient()\n",
    "\n",
    "source = {\"image_uri\": image_url}\n",
    "image = {\"source\": source}\n",
    "features = [\n",
    "    {\"type_\": vision_v1.Feature.Type.LABEL_DETECTION},\n",
    "    {\"type_\": vision_v1.Feature.Type.IMAGE_PROPERTIES},\n",
    "]\n",
    "\n",
    "# Each requests element corresponds to a single image.  To annotate more\n",
    "# images, create a request element for each image and add it to\n",
    "# the array of requests\n",
    "# request = [{\"image\": image, \"features\": features}]\n",
    "response = client.annotate_image({'image': image, 'features': features})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[mid: \"/m/0csby\"\n",
       "description: \"Cloud\"\n",
       "score: 0.9762179851531982\n",
       "topicality: 0.9762179851531982\n",
       ", mid: \"/m/01bqvp\"\n",
       "description: \"Sky\"\n",
       "score: 0.9716936349868774\n",
       "topicality: 0.9716936349868774\n",
       ", mid: \"/m/05s2s\"\n",
       "description: \"Plant\"\n",
       "score: 0.9571888446807861\n",
       "topicality: 0.9571888446807861\n",
       ", mid: \"/m/05wrt\"\n",
       "description: \"Property\"\n",
       "score: 0.9435440301895142\n",
       "topicality: 0.9435440301895142\n",
       ", mid: \"/m/07j7r\"\n",
       "description: \"Tree\"\n",
       "score: 0.8947656750679016\n",
       "topicality: 0.8947656750679016\n",
       ", mid: \"/m/0d4v4\"\n",
       "description: \"Window\"\n",
       "score: 0.8766854405403137\n",
       "topicality: 0.8766854405403137\n",
       ", mid: \"/m/0hndl\"\n",
       "description: \"Shade\"\n",
       "score: 0.8734689950942993\n",
       "topicality: 0.8734689950942993\n",
       ", mid: \"/m/02dgv\"\n",
       "description: \"Door\"\n",
       "score: 0.8631654977798462\n",
       "topicality: 0.8631654977798462\n",
       ", mid: \"/m/025s3q0\"\n",
       "description: \"Landscape\"\n",
       "score: 0.8003847002983093\n",
       "topicality: 0.8003847002983093\n",
       ", mid: \"/m/02nfxt\"\n",
       "description: \"Residential area\"\n",
       "score: 0.7925867438316345\n",
       "topicality: 0.7925867438316345\n",
       "]"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "response.label_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dominant_colors {\n",
       "  colors {\n",
       "    color {\n",
       "      red: 195.0\n",
       "      green: 209.0\n",
       "      blue: 236.0\n",
       "    }\n",
       "    score: 0.16373702883720398\n",
       "    pixel_fraction: 0.21503496170043945\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 223.0\n",
       "      green: 192.0\n",
       "      blue: 130.0\n",
       "    }\n",
       "    score: 0.0979471206665039\n",
       "    pixel_fraction: 0.012723388150334358\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 99.0\n",
       "      green: 80.0\n",
       "      blue: 54.0\n",
       "    }\n",
       "    score: 0.05041574314236641\n",
       "    pixel_fraction: 0.026903651654720306\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 115.0\n",
       "      green: 74.0\n",
       "      blue: 29.0\n",
       "    }\n",
       "    score: 0.04885847494006157\n",
       "    pixel_fraction: 0.010489510372281075\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 74.0\n",
       "      green: 43.0\n",
       "      blue: 19.0\n",
       "    }\n",
       "    score: 0.04260444641113281\n",
       "    pixel_fraction: 0.010101010091602802\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 41.0\n",
       "      green: 95.0\n",
       "      blue: 25.0\n",
       "    }\n",
       "    score: 0.0040482827462255955\n",
       "    pixel_fraction: 0.05953768268227577\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 184.0\n",
       "      green: 151.0\n",
       "      blue: 92.0\n",
       "    }\n",
       "    score: 0.05859631672501564\n",
       "    pixel_fraction: 0.010003885254263878\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 146.0\n",
       "      green: 116.0\n",
       "      blue: 62.0\n",
       "    }\n",
       "    score: 0.04203253239393234\n",
       "    pixel_fraction: 0.009518259204924107\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 250.0\n",
       "      green: 225.0\n",
       "      blue: 162.0\n",
       "    }\n",
       "    score: 0.039083369076251984\n",
       "    pixel_fraction: 0.005341880489140749\n",
       "  }\n",
       "  colors {\n",
       "    color {\n",
       "      red: 107.0\n",
       "      green: 80.0\n",
       "      blue: 31.0\n",
       "    }\n",
       "    score: 0.039019037038087845\n",
       "    pixel_fraction: 0.00971250981092453\n",
       "  }\n",
       "}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "response.image_properties_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "google.cloud.vision_v1.types.image_annotator.DominantColorsAnnotation"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "type(response.image_properties_annotation.dominant_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "len(response.image_properties_annotation.dominant_colors.colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "red: 195.0\n",
       "green: 209.0\n",
       "blue: 236.0"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "response.image_properties_annotation.dominant_colors.colors[0].color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "195.0"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "response.image_properties_annotation.dominant_colors.colors[0].color.red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "mid: \"/m/0csby\"\n",
       "description: \"Cloud\"\n",
       "score: 0.9762179851531982\n",
       "topicality: 0.9762179851531982"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "response.label_annotations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Cloud'"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "response.label_annotations[0].description"
   ]
  },
  {
   "source": [
    "### Algorithm Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate Test Data\n",
    "image_urls = [\"https://cdn.homedsgn.com/wp-content/uploads/2016/02/Contemporary-House-02-850x567.jpg\", \"https://cdn.vox-cdn.com/thumbor/F457EVG_FXKJAQi4WPguloiJgfE=/0x0:1024x682/1200x800/filters:focal(428x194:590x356)/cdn.vox-cdn.com/uploads/chorus_image/image/56731467/2.0.jpeg\", \"https://ap.rdcpix.com/4d64d3cd2c39c8042a7adc2ce4801187l-m2010213622od-w1024_h768_x2.webp\"]\n",
    "\n",
    "listings = []\n",
    "for i, url in enumerate(image_urls):\n",
    "    listings.append({\n",
    "        'id': i,\n",
    "        'photo': url,\n",
    "        'tags': [],\n",
    "        'colors': [],\n",
    "        'tag_score': 0.0,\n",
    "        'color_score': 0.0\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'photo': 'https://cdn.homedsgn.com/wp-content/uploads/2016/02/Contemporary-House-02-850x567.jpg',\n",
       "  'tags': [],\n",
       "  'colors': [],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0},\n",
       " {'id': 1,\n",
       "  'photo': 'https://cdn.vox-cdn.com/thumbor/F457EVG_FXKJAQi4WPguloiJgfE=/0x0:1024x682/1200x800/filters:focal(428x194:590x356)/cdn.vox-cdn.com/uploads/chorus_image/image/56731467/2.0.jpeg',\n",
       "  'tags': [],\n",
       "  'colors': [],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0},\n",
       " {'id': 2,\n",
       "  'photo': 'https://ap.rdcpix.com/4d64d3cd2c39c8042a7adc2ce4801187l-m2010213622od-w1024_h768_x2.webp',\n",
       "  'tags': [],\n",
       "  'colors': [],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0}]"
      ]
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_vision(image_url):\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    source = {\"image_uri\": image_url}\n",
    "    image = {\"source\": source}\n",
    "    features = [\n",
    "        {\"type_\": vision_v1.Feature.Type.LABEL_DETECTION},\n",
    "        {\"type_\": vision_v1.Feature.Type.IMAGE_PROPERTIES},\n",
    "    ]\n",
    "\n",
    "    return client.annotate_image({'image': image, 'features': features})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the tags and colors for each lisitng \n",
    "for listing in listings:\n",
    "    response = google_vision(listing['photo'])\n",
    "    tags = set() # to remove duplicate labels\n",
    "    for label in response.label_annotations:\n",
    "        tags.add(label.description)\n",
    "        # listing['tags'].append(label.description)\n",
    "    listing['tags'] += tags\n",
    "    for color in response.image_properties_annotation.dominant_colors.colors:\n",
    "        listing['colors'].append([color.color.red, color.color.green, color.color.blue])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'photo': 'https://cdn.homedsgn.com/wp-content/uploads/2016/02/Contemporary-House-02-850x567.jpg',\n",
       "  'tags': ['Window',\n",
       "   'Door',\n",
       "   'Architecture',\n",
       "   'Property',\n",
       "   'Residential area',\n",
       "   'Building',\n",
       "   'Tree',\n",
       "   'Plant',\n",
       "   'Cloud',\n",
       "   'Sky'],\n",
       "  'colors': [[224.0, 228.0, 234.0],\n",
       "   [190.0, 201.0, 219.0],\n",
       "   [26.0, 20.0, 16.0],\n",
       "   [199.0, 206.0, 215.0],\n",
       "   [157.0, 156.0, 150.0],\n",
       "   [170.0, 156.0, 128.0],\n",
       "   [127.0, 117.0, 92.0],\n",
       "   [119.0, 117.0, 112.0],\n",
       "   [210.0, 218.0, 236.0],\n",
       "   [177.0, 156.0, 98.0]],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0},\n",
       " {'id': 1,\n",
       "  'photo': 'https://cdn.vox-cdn.com/thumbor/F457EVG_FXKJAQi4WPguloiJgfE=/0x0:1024x682/1200x800/filters:focal(428x194:590x356)/cdn.vox-cdn.com/uploads/chorus_image/image/56731467/2.0.jpeg',\n",
       "  'tags': ['Window',\n",
       "   'Fixture',\n",
       "   'Grass',\n",
       "   'Property',\n",
       "   'Residential area',\n",
       "   'House',\n",
       "   'Building',\n",
       "   'Tree',\n",
       "   'Plant',\n",
       "   'Sky'],\n",
       "  'colors': [[192.0, 194.0, 184.0],\n",
       "   [162.0, 159.0, 136.0],\n",
       "   [157.0, 161.0, 150.0],\n",
       "   [192.0, 190.0, 168.0],\n",
       "   [123.0, 120.0, 96.0],\n",
       "   [89.0, 85.0, 58.0],\n",
       "   [117.0, 122.0, 112.0],\n",
       "   [61.0, 57.0, 32.0],\n",
       "   [221.0, 224.0, 214.0],\n",
       "   [83.0, 90.0, 82.0]],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0},\n",
       " {'id': 2,\n",
       "  'photo': 'https://ap.rdcpix.com/4d64d3cd2c39c8042a7adc2ce4801187l-m2010213622od-w1024_h768_x2.webp',\n",
       "  'tags': ['Window',\n",
       "   'Door',\n",
       "   'Neighbourhood',\n",
       "   'Land lot',\n",
       "   'Stairs',\n",
       "   'House',\n",
       "   'Building',\n",
       "   'Plant',\n",
       "   'Sky',\n",
       "   'Cottage'],\n",
       "  'colors': [[165.0, 155.0, 125.0],\n",
       "   [81.0, 85.0, 88.0],\n",
       "   [96.0, 118.0, 146.0],\n",
       "   [30.0, 49.0, 75.0],\n",
       "   [106.0, 87.0, 28.0],\n",
       "   [130.0, 186.0, 242.0],\n",
       "   [134.0, 120.0, 93.0],\n",
       "   [154.0, 155.0, 152.0],\n",
       "   [68.0, 88.0, 112.0],\n",
       "   [119.0, 120.0, 119.0]],\n",
       "  'tag_score': 0.0,\n",
       "  'color_score': 0.0}]"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "listings"
   ]
  },
  {
   "source": [
    "### Content-Based Filtering\n",
    "TF-IDF image label similarity "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = pd.DataFrame()\n",
    "tag_df['listing_id'] = [listing['id'] for listing in listings]\n",
    "tags_text = []\n",
    "for listing in listings:\n",
    "    text = \"\"\n",
    "    for tag in listing['tags']:\n",
    "        text += tag + \" \"\n",
    "    tags_text.append(text)\n",
    "    \n",
    "tag_df['tags_text'] = tags_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   listing_id                                          tags_text\n",
       "0           0  Window Door Architecture Property Residential ...\n",
       "1           1  Window Fixture Grass Property Residential area...\n",
       "2           2  Window Door Neighbourhood Land lot Stairs Hous..."
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>listing_id</th>\n      <th>tags_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Window Door Architecture Property Residential ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Window Fixture Grass Property Residential area...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Window Door Neighbourhood Land lot Stairs Hous...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "tag_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 89
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(tag_df['tags_text'])\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(0, 0.5899039882772596), (1, 0.9999999999999998), (2, 0.28642880198693627)]"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "sim_scores = list(enumerate(cosine_sim[1]))\n",
    "# sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "sim_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, score in sim_scores:\n",
    "    listings[i]['tag_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5899039882772596"
      ]
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "listings[0]['tag_score']"
   ]
  },
  {
   "source": [
    "### Cosine Similarity of Colors\n",
    "RGB vectors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "vector1 = [1, 2, 3]\n",
    "vector2 = [3, 2, 1]\n",
    "\n",
    "1 - distance.cosine(vector1, vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for listing in listings:\n",
    "    for color in listing['colors']:\n",
    "        cos_sim = 1 - distance.cosine(color, listings[1]['colors'][0])\n",
    "        listing['color_score'] = max(listing['color_score'], cos_sim)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'photo': 'https://cdn.homedsgn.com/wp-content/uploads/2016/02/Contemporary-House-02-850x567.jpg',\n",
       "  'tags': ['Window',\n",
       "   'Door',\n",
       "   'Architecture',\n",
       "   'Property',\n",
       "   'Residential area',\n",
       "   'Building',\n",
       "   'Tree',\n",
       "   'Plant',\n",
       "   'Cloud',\n",
       "   'Sky'],\n",
       "  'colors': [[224.0, 228.0, 234.0],\n",
       "   [190.0, 201.0, 219.0],\n",
       "   [26.0, 20.0, 16.0],\n",
       "   [199.0, 206.0, 215.0],\n",
       "   [157.0, 156.0, 150.0],\n",
       "   [170.0, 156.0, 128.0],\n",
       "   [127.0, 117.0, 92.0],\n",
       "   [119.0, 117.0, 112.0],\n",
       "   [210.0, 218.0, 236.0],\n",
       "   [177.0, 156.0, 98.0]],\n",
       "  'tag_score': 0.5899039882772596,\n",
       "  'color_score': 0.9999728497925675},\n",
       " {'id': 1,\n",
       "  'photo': 'https://cdn.vox-cdn.com/thumbor/F457EVG_FXKJAQi4WPguloiJgfE=/0x0:1024x682/1200x800/filters:focal(428x194:590x356)/cdn.vox-cdn.com/uploads/chorus_image/image/56731467/2.0.jpeg',\n",
       "  'tags': ['Window',\n",
       "   'Fixture',\n",
       "   'Grass',\n",
       "   'Property',\n",
       "   'Residential area',\n",
       "   'House',\n",
       "   'Building',\n",
       "   'Tree',\n",
       "   'Plant',\n",
       "   'Sky'],\n",
       "  'colors': [[192.0, 194.0, 184.0],\n",
       "   [162.0, 159.0, 136.0],\n",
       "   [157.0, 161.0, 150.0],\n",
       "   [192.0, 190.0, 168.0],\n",
       "   [123.0, 120.0, 96.0],\n",
       "   [89.0, 85.0, 58.0],\n",
       "   [117.0, 122.0, 112.0],\n",
       "   [61.0, 57.0, 32.0],\n",
       "   [221.0, 224.0, 214.0],\n",
       "   [83.0, 90.0, 82.0]],\n",
       "  'tag_score': 0.9999999999999998,\n",
       "  'color_score': 1},\n",
       " {'id': 2,\n",
       "  'photo': 'https://ap.rdcpix.com/4d64d3cd2c39c8042a7adc2ce4801187l-m2010213622od-w1024_h768_x2.webp',\n",
       "  'tags': ['Window',\n",
       "   'Door',\n",
       "   'Neighbourhood',\n",
       "   'Land lot',\n",
       "   'Stairs',\n",
       "   'House',\n",
       "   'Building',\n",
       "   'Plant',\n",
       "   'Sky',\n",
       "   'Cottage'],\n",
       "  'colors': [[165.0, 155.0, 125.0],\n",
       "   [81.0, 85.0, 88.0],\n",
       "   [96.0, 118.0, 146.0],\n",
       "   [30.0, 49.0, 75.0],\n",
       "   [106.0, 87.0, 28.0],\n",
       "   [130.0, 186.0, 242.0],\n",
       "   [134.0, 120.0, 93.0],\n",
       "   [154.0, 155.0, 152.0],\n",
       "   [68.0, 88.0, 112.0],\n",
       "   [119.0, 120.0, 119.0]],\n",
       "  'tag_score': 0.28642880198693627,\n",
       "  'color_score': 0.9998912473808048}]"
      ]
     },
     "metadata": {},
     "execution_count": 106
    }
   ],
   "source": [
    "listings"
   ]
  },
  {
   "source": [
    "### OpenCV Testing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_processing import process_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}